# weaHTR config file
#
# All mentioned variables are required
# note that the YML file is indentation
# sensitive so only adjust the variable
# names, or be careful when re-ordering
# things.
---

#--- general settings ---

# the configuration profile name
# set this to a unique value per
# profile and will affect the
# naming convention on output
# generated (for reproducibility)
profile_name: "format_1_month"

# where to output analysis data
# this includes cropping and
# template matching settings
# as well as the ML labels
# and log files (failed attempts)
# this directory will be created if
# it does not exist
output: "/docker_data_dir/output/"

#--- template matching settings ---

# scale factor of image inputs - to speed up processing
# and increase accuracy, the larger the table on the image
# the smaller this value can be
# for an almost fully covered image a value of 0.25 is good
# for tables covering less 0.5 (less shrinking) yields
# better results
scale_ratio: 0.25

# adaptive thresholding settings
# [check logs and noise levels on template matching
# previews to get insights into potential issues]
# See opencv documentation at
# https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html
# on blockSize (window_size) and C under adaptive thresholding
threshold:
 window_size: 91
 C: 6

# these set hard bounds on some of the template matching methods
# for example it limits translation or rotation over certain values
# as those would be unrealistic (given a good data
# acquisition protocol)
features:
 max_features: 20000 # maximum number of features to generate
 translation_tolerance: 1000 # only allow translations X/Y pixels or less

fft:
 rotation_tolerance: 10 # only allow rotations of 10 degrees or less
 translation_tolerance: 1000 # only allow translations X/Y pixels or less
 scale_tolerance: 2 # scale factor can not exceed this value

#--- transcription settings ---

# padding factor fraction of the width height to
# be added on either side of the selection
# cell width +_ (cell width * x_pad)
# cell height +_ (cell height * y_pad)
x_pad: 0
y_pad: 0

# soft validation, soft validation creates N (10)
# augmented images from the original, these
# are slightly altered versions which should
# give an idea of the robustness of the
# transcription (only the majority class, and
# the mean confidence values are stored)
soft_val: 10

#--- machine learning settings ---

# training settings
augmentation: True
learning_rate:
epochs: 10
batch_size: 4

# prediction settings
device: "cpu"

# model specific settings
tesseract:
 path: "/usr/share/tesseract-ocr/5/tessdata/"
 model: "cobecore-V6.traineddata"
 config: '--psm 8 -c tessedit_char_whitelist=0123456789.,'

trocr:
 custom_path: "./models/TrOCR/"
 model: "microsoft/trocr-base-stage1"
 processor: "microsoft/trocr-base-handwritten"
